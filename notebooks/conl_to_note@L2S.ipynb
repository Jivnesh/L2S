{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conll to note format for sanskrit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Rename the files to gold and silver\n",
    "# import argparse\n",
    "# import os\n",
    "# path = './data/train_20k/'\n",
    "# count = 0\n",
    "# for file in os.listdir(path):\n",
    "#         count= count + 1\n",
    "#         dst =\"Silver_\" + str(count) + \".csv\"\n",
    "#         src =file\n",
    "#         os.rename(path+src,path+dst) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language: san Split: train_20k Num. Sentences: 20297 \n",
      "creating sanskrit_treebank/ud_pos_ner_dp_train_20k_san\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "path = './sanskrit_treebank/'\n",
    "languages_for_low_resource = ['san']\n",
    "languages = sorted(list(set(languages_for_low_resource)))\n",
    "#\n",
    "splits = ['train_20k']\n",
    "lng_to_files = dict((language, {}) for language in languages)\n",
    "for language, d in lng_to_files.items():\n",
    "    for split in splits:\n",
    "        d[split] = []\n",
    "    lng_to_files[language] = d\n",
    "sub_folders = os.listdir(path)\n",
    "for sub_folder in sub_folders:\n",
    "    if sub_folder != 'train_20k':\n",
    "        continue\n",
    "    folder = os.path.join(path, sub_folder)\n",
    "    files = sorted(os.listdir(folder))\n",
    "    for file in files:\n",
    "        full_path = os.path.join(folder, file)\n",
    "        lng_to_files[language][sub_folder].append(full_path)\n",
    "tag = set()\n",
    "for language, split_dict in lng_to_files.items():\n",
    "    posi =set()\n",
    "    for split, files in split_dict.items():\n",
    "        sentences = []\n",
    "        num_sentences = 0\n",
    "        for file in files:\n",
    "            num_sentences += 1\n",
    "            flag = 0\n",
    "            with open(file, 'r') as file:\n",
    "                for line in file:\n",
    "                    new_line = []\n",
    "                    line = line.strip()\n",
    "#                     print(line)\n",
    "                    if flag == 0:\n",
    "                        flag = 1\n",
    "                        continue\n",
    "                    tokens = line.split(',')\n",
    "                    id = str(int(tokens[0]) + 1)\n",
    "                    word = tokens[1]\n",
    "                    ############################\n",
    "                    # To add rule features id of rule is given\n",
    "                    lemma = tokens[2]\n",
    "                    pos = tokens[3]\n",
    "                    tag.add(pos)\n",
    "                    if tokens[6]:\n",
    "                        arc_tag = tokens[5]\n",
    "                        head = str(int(tokens[6]) + 1)\n",
    "                    else:\n",
    "                        arc_tag = 'root'\n",
    "                        head = '0'\n",
    "                    new_line = [id, word, pos, lemma, head, arc_tag]\n",
    "                    posi.add(pos)\n",
    "#                     print(new_line)\n",
    "                    sentences.append(new_line)\n",
    "            sentences.append([])   \n",
    "        \n",
    "        print('Language: %s Split: %s Num. Sentences: %s ' % (language, split, num_sentences))\n",
    "        if not os.path.exists('data'):\n",
    "            os.makedirs('data')\n",
    "        write_data_path = 'sanskrit_treebank/ud_pos_ner_dp_' + split + '_' + language\n",
    "        print('creating %s' % write_data_path)\n",
    "        with open(write_data_path, 'w') as f:\n",
    "            for line in sentences:\n",
    "                f.write('\\t'.join(line) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build 1-hot for POS embedding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension is 475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jivnesh/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# define example\n",
    "# data = ['cold', 'cold', 'warm', 'cold', 'hot', 'hot', 'warm', 'cold', 'warm', 'hot']\n",
    "data = list(tag)\n",
    "values = array(data)\n",
    "# print(values)\n",
    "# integer encode\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(values)\n",
    "# print(integer_encoded)\n",
    "# binary encode\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "# print(onehot_encoded)\n",
    "print('Dimension is',len(onehot_encoded[0]))\n",
    "# # invert first example\n",
    "# inverted = label_encoder.inverse_transform([argmax(onehot_encoded[0, :])])\n",
    "# print(inverted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "475\n"
     ]
    }
   ],
   "source": [
    "# onehot_encoded[0]\n",
    "count =0 \n",
    "with open(\"pos_embedding_1_hot.475\", \"w\") as f:   \n",
    "    f.write(str(len(tag))+' '+str(475)+'\\n')\n",
    "    for word in tag:\n",
    "        word=word+'@'\n",
    "        f.write(word) \n",
    "        for v in onehot_encoded[count]:\n",
    "            f.write(' '+str(v))\n",
    "        f.write('\\n')\n",
    "        count = count + 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22500"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27375"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 0\n",
    "for a,b in splits:\n",
    "    s = s+ a + b\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4875"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s-total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 250 0\n",
      "2 250 0\n",
      "3 250 0\n",
      "4 250 0\n",
      "5 250 0\n",
      "6 245 5\n",
      "7 240 10\n",
      "8 235 15\n",
      "9 230 20\n",
      "10 225 25\n",
      "11 220 30\n",
      "12 215 35\n",
      "13 210 40\n",
      "14 205 45\n",
      "15 200 50\n",
      "16 195 55\n",
      "17 190 60\n",
      "18 185 65\n",
      "19 180 70\n",
      "20 175 75\n",
      "21 170 80\n",
      "22 165 85\n",
      "23 160 90\n",
      "24 155 95\n",
      "25 150 100\n",
      "26 145 105\n",
      "27 140 110\n",
      "28 135 115\n",
      "29 130 120\n",
      "30 125 125\n",
      "31 120 130\n",
      "32 115 135\n",
      "33 110 140\n",
      "34 105 145\n",
      "35 100 150\n",
      "36 95 155\n",
      "37 90 160\n",
      "38 85 165\n",
      "39 80 170\n",
      "40 75 175\n",
      "41 70 180\n",
      "42 65 185\n",
      "43 60 190\n",
      "44 55 195\n",
      "45 50 200\n",
      "46 45 205\n",
      "47 40 210\n",
      "48 35 215\n",
      "49 30 220\n",
      "50 25 225\n",
      "51 20 230\n",
      "52 15 235\n",
      "53 10 240\n",
      "54 5 245\n",
      "55 0 250\n",
      "56 0 250\n",
      "57 0 250\n",
      "58 0 250\n",
      "59 0 250\n",
      "60 0 250\n",
      "61 0 250\n",
      "62 0 250\n",
      "63 0 250\n",
      "64 0 250\n",
      "65 0 250\n",
      "66 0 250\n",
      "67 0 250\n",
      "68 0 250\n",
      "69 0 250\n",
      "70 0 250\n",
      "71 0 250\n",
      "72 0 250\n",
      "73 0 250\n",
      "74 0 250\n",
      "75 0 250\n",
      "76 0 250\n",
      "77 0 250\n",
      "78 0 250\n",
      "79 0 250\n",
      "80 0 250\n",
      "81 0 250\n",
      "82 0 250\n",
      "83 0 250\n",
      "84 0 250\n",
      "85 0 250\n",
      "86 0 250\n",
      "87 0 250\n",
      "88 0 250\n",
      "89 0 250\n",
      "90 0 250\n",
      "91 0 250\n",
      "92 0 250\n",
      "93 0 250\n",
      "94 0 250\n",
      "95 0 250\n",
      "96 0 250\n",
      "97 0 250\n",
      "98 0 250\n",
      "99 0 250\n",
      "100 0 250\n",
      "101 0 250\n",
      "102 0 250\n",
      "103 0 250\n",
      "104 0 250\n",
      "105 0 250\n",
      "106 0 250\n",
      "107 0 250\n",
      "108 0 250\n",
      "109 0 250\n",
      "110 0 125\n"
     ]
    }
   ],
   "source": [
    "# gold = 2495\n",
    "# silver = 20297\n",
    "gold = 2500\n",
    "silver = 20000\n",
    "total = gold+silver\n",
    "batchsize = 250\n",
    "sums = 0\n",
    "deduction = 5\n",
    "count = 0\n",
    "inter = 1\n",
    "splits = list()\n",
    "while(sums<total):\n",
    "    while(count<5):\n",
    "        sums+=batchsize\n",
    "        gold -=batchsize\n",
    "        print(inter,batchsize,0)\n",
    "        splits.append([batchsize,0])\n",
    "#         print('Gold',gold)\n",
    "#         print('Silver',silver)\n",
    "        inter+=1\n",
    "        count +=1\n",
    "    if gold-deduction and deduction<batchsize :\n",
    "        print(inter,batchsize-deduction,deduction)\n",
    "        splits.append([batchsize-deduction,deduction])\n",
    "        inter+=1\n",
    "        gold -= (batchsize-deduction)\n",
    "        silver -= deduction\n",
    "#         print('Gold',gold)\n",
    "#         print('Silver',silver)\n",
    "        sums+=batchsize\n",
    "        deduction += 5\n",
    "    else:\n",
    "#         print('Gold',gold)\n",
    "# #         print(inter,gold,batchsize- gold)\n",
    "#         inter+=1\n",
    "#         silver -= batchsize- gold\n",
    "# #         print('Gold',gold)\n",
    "# #         print('Silver',silver)\n",
    "        gold = 0\n",
    "        \n",
    "        sums+=batchsize\n",
    "    while gold == 0 and silver- batchsize> 0:\n",
    "        print(inter,0,batchsize)\n",
    "        splits.append([0,batchsize])\n",
    "        inter+=1\n",
    "        silver -= batchsize\n",
    "        sums+=batchsize\n",
    "#         print('Gold',gold)\n",
    "#         print('Silver',silver)\n",
    "    if silver- batchsize< 0:\n",
    "        print(inter,0,silver)\n",
    "        splits.append([0,silver])\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
